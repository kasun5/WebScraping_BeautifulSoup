{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraper using Beautiful Soup test_1.0\n",
    "\n",
    "This notebook consists of basic web scraping code that used **requests** and **Beautiful Soup** packages. For this test, [Fake Python](https://realpython.github.io/fake-jobs/) site is used.\n",
    "\n",
    "### Access Website and Read Elemets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send an HTTP get request to the URL, and retrieve HTML data that server sends back. Response **.headers** will give access to information about retireved data. Accoeding to the 'Content-Type', the retrieve data is 'text/html'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Connection': 'keep-alive', 'Content-Length': '5721', 'Server': 'GitHub.com', 'Content-Type': 'text/html; charset=utf-8', 'permissions-policy': 'interest-cohort=()', 'Last-Modified': 'Mon, 12 Apr 2021 09:01:55 GMT', 'Access-Control-Allow-Origin': '*', 'ETag': 'W/\"60740c83-197ed\"', 'expires': 'Wed, 17 May 2023 04:06:48 GMT', 'Cache-Control': 'max-age=600', 'Content-Encoding': 'gzip', 'x-proxy-cache': 'MISS', 'X-GitHub-Request-Id': 'ACB6:4CDF:3AE6E50:5ABBFDE:64645080', 'Accept-Ranges': 'bytes', 'Date': 'Wed, 17 May 2023 05:29:03 GMT', 'Via': '1.1 varnish', 'Age': '0', 'X-Served-By': 'cache-dfw-kdfw8210048-DFW', 'X-Cache': 'HIT', 'X-Cache-Hits': '1', 'X-Timer': 'S1684301343.330582,VS0,VE46', 'Vary': 'Accept-Encoding', 'X-Fastly-Request-ID': '83f46ae9feb72fc9fba7b5205f68e5908a84e60c'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL for the website we gonna scrape\n",
    "URL = \"https://realpython.github.io/fake-jobs/\"\n",
    "# request HTML data from the url page\n",
    "page = requests.get(URL)\n",
    "page.headers\n",
    "#print(page.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library for pulling data out of HTML and XML files. Beautiful Soup object was created and parsed the html page content through the html parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create beautifulSoup object \"s\"\n",
    "# 1st element is html contest requested earlier\n",
    "# 2nd elemet is apropiate parser, this time html parser\n",
    "s = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the HTML element by ID that contains all the job listings. You can use **.prettify()** function to see all the HTML contained within the div id tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = s.find(id=\"ResultsContainer\")\n",
    "#print(results.prettify())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the **ResultsContainer** ID, every job posting is wrapped in a div element with the class **card-content**. Use **.find_all()** to get all the HTML jobs data from the results Beautiful Soup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_elements = results.find_all(\"div\", class_=\"card-content\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **.find()** to access child elemets of each job. Use **.text** to return the text portions of the html elemet tags and **.strip()** to remove leading and trailing whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senior Python Developer\n",
      "Payne, Roberts and Davis\n",
      "Stewartbury, AA\n",
      "\n",
      "Energy engineer\n",
      "Vasquez-Davidson\n",
      "Christopherville, AA\n",
      "\n",
      "Legal executive\n",
      "Jackson, Chambers and Levy\n",
      "Port Ericaburgh, AA\n",
      "\n",
      "Fitness centre manager\n",
      "Savage-Bradley\n",
      "East Seanview, AP\n",
      "\n",
      "Product manager\n",
      "Ramirez Inc\n",
      "North Jamieview, AP\n",
      "\n",
      "Medical technical officer\n",
      "Rogers-Yates\n",
      "Davidville, AP\n",
      "\n",
      "Physiological scientist\n",
      "Kramer-Klein\n",
      "South Christopher, AE\n",
      "\n",
      "Textile designer\n",
      "Meyers-Johnson\n",
      "Port Jonathan, AE\n",
      "\n",
      "Television floor manager\n",
      "Hughes-Williams\n",
      "Osbornetown, AE\n",
      "\n",
      "Waste management officer\n",
      "Jones, Williams and Villa\n",
      "Scotttown, AP\n",
      "\n",
      "Software Engineer (Python)\n",
      "Garcia PLC\n",
      "Ericberg, AE\n",
      "\n",
      "Interpreter\n",
      "Gregory and Sons\n",
      "Ramireztown, AE\n",
      "\n",
      "Architect\n",
      "Clark, Garcia and Sosa\n",
      "Figueroaview, AA\n",
      "\n",
      "Meteorologist\n",
      "Bush PLC\n",
      "Kelseystad, AA\n",
      "\n",
      "Audiological scientist\n",
      "Salazar-Meyers\n",
      "Williamsburgh, AE\n",
      "\n",
      "English as a second language teacher\n",
      "Parker, Murphy and Brooks\n",
      "Mitchellburgh, AE\n",
      "\n",
      "Surgeon\n",
      "Cruz-Brown\n",
      "West Jessicabury, AA\n",
      "\n",
      "Equities trader\n",
      "Macdonald-Ferguson\n",
      "Maloneshire, AE\n",
      "\n",
      "Newspaper journalist\n",
      "Williams, Peterson and Rojas\n",
      "Johnsonton, AA\n",
      "\n",
      "Materials engineer\n",
      "Smith and Sons\n",
      "South Davidtown, AP\n",
      "\n",
      "Python Programmer (Entry-Level)\n",
      "Moss, Duncan and Allen\n",
      "Port Sara, AE\n",
      "\n",
      "Product/process development scientist\n",
      "Gomez-Carroll\n",
      "Marktown, AA\n",
      "\n",
      "Scientist, research (maths)\n",
      "Manning, Welch and Herring\n",
      "Laurenland, AE\n",
      "\n",
      "Ecologist\n",
      "Lee, Gutierrez and Brown\n",
      "Lauraton, AP\n",
      "\n",
      "Materials engineer\n",
      "Davis, Serrano and Cook\n",
      "South Tammyberg, AP\n",
      "\n",
      "Historic buildings inspector/conservation officer\n",
      "Smith LLC\n",
      "North Brandonville, AP\n",
      "\n",
      "Data scientist\n",
      "Thomas Group\n",
      "Port Robertfurt, AA\n",
      "\n",
      "Psychiatrist\n",
      "Silva-King\n",
      "Burnettbury, AE\n",
      "\n",
      "Structural engineer\n",
      "Pierce-Long\n",
      "Herbertside, AA\n",
      "\n",
      "Immigration officer\n",
      "Walker-Simpson\n",
      "Christopherport, AP\n",
      "\n",
      "Python Programmer (Entry-Level)\n",
      "Cooper and Sons\n",
      "West Victor, AE\n",
      "\n",
      "Neurosurgeon\n",
      "Donovan, Gonzalez and Figueroa\n",
      "Port Aaron, AP\n",
      "\n",
      "Broadcast engineer\n",
      "Morgan, Butler and Bennett\n",
      "Loribury, AA\n",
      "\n",
      "Make\n",
      "Snyder-Lee\n",
      "Angelastad, AP\n",
      "\n",
      "Nurse, adult\n",
      "Harris PLC\n",
      "Larrytown, AE\n",
      "\n",
      "Air broker\n",
      "Washington PLC\n",
      "West Colin, AP\n",
      "\n",
      "Editor, film/video\n",
      "Brown, Price and Campbell\n",
      "West Stephanie, AP\n",
      "\n",
      "Production assistant, radio\n",
      "Mcgee PLC\n",
      "Laurentown, AP\n",
      "\n",
      "Engineer, communications\n",
      "Dixon Inc\n",
      "Wrightberg, AP\n",
      "\n",
      "Sales executive\n",
      "Thompson, Sheppard and Ward\n",
      "Alberttown, AE\n",
      "\n",
      "Software Developer (Python)\n",
      "Adams-Brewer\n",
      "Brockburgh, AE\n",
      "\n",
      "Futures trader\n",
      "Schneider-Brady\n",
      "North Jason, AE\n",
      "\n",
      "Tour manager\n",
      "Gonzales-Frank\n",
      "Arnoldhaven, AE\n",
      "\n",
      "Cytogeneticist\n",
      "Smith-Wong\n",
      "Lake Destiny, AP\n",
      "\n",
      "Designer, multimedia\n",
      "Pierce-Herrera\n",
      "South Timothyburgh, AP\n",
      "\n",
      "Trade union research officer\n",
      "Aguilar, Rivera and Quinn\n",
      "New Jimmyton, AE\n",
      "\n",
      "Chemist, analytical\n",
      "Lowe, Barnes and Thomas\n",
      "New Lucasbury, AP\n",
      "\n",
      "Programmer, multimedia\n",
      "Lewis, Gonzalez and Vasquez\n",
      "Port Cory, AE\n",
      "\n",
      "Engineer, broadcasting (operations)\n",
      "Taylor PLC\n",
      "Gileston, AA\n",
      "\n",
      "Teacher, primary school\n",
      "Oliver, Jones and Ramirez\n",
      "Cindyshire, AA\n",
      "\n",
      "Python Developer\n",
      "Rivera and Sons\n",
      "East Michaelfort, AA\n",
      "\n",
      "Manufacturing systems engineer\n",
      "Garcia PLC\n",
      "Joybury, AE\n",
      "\n",
      "Producer, television/film/video\n",
      "Johnson, Wells and Kramer\n",
      "Emmatown, AE\n",
      "\n",
      "Scientist, forensic\n",
      "Gonzalez LLC\n",
      "Colehaven, AP\n",
      "\n",
      "Bonds trader\n",
      "Morgan, White and Macdonald\n",
      "Port Coryton, AE\n",
      "\n",
      "Editorial assistant\n",
      "Robinson-Fitzpatrick\n",
      "Amyborough, AA\n",
      "\n",
      "Photographer\n",
      "Waters, Wilson and Hoover\n",
      "Reynoldsville, AA\n",
      "\n",
      "Retail banker\n",
      "Hill LLC\n",
      "Port Billy, AP\n",
      "\n",
      "Jewellery designer\n",
      "Li-Gregory\n",
      "Adamburgh, AA\n",
      "\n",
      "Ophthalmologist\n",
      "Fisher, Ryan and Coleman\n",
      "Wilsonmouth, AA\n",
      "\n",
      "Back-End Web Developer (Python, Django)\n",
      "Stewart-Alexander\n",
      "South Kimberly, AA\n",
      "\n",
      "Licensed conveyancer\n",
      "Abbott and Sons\n",
      "Benjaminland, AP\n",
      "\n",
      "Futures trader\n",
      "Bryant, Santana and Davenport\n",
      "Zacharyport, AA\n",
      "\n",
      "Counselling psychologist\n",
      "Smith PLC\n",
      "Port Devonville, AE\n",
      "\n",
      "Insurance underwriter\n",
      "Patterson-Singh\n",
      "East Thomas, AE\n",
      "\n",
      "Engineer, automotive\n",
      "Martinez-Berry\n",
      "New Jeffrey, AP\n",
      "\n",
      "Producer, radio\n",
      "May, Taylor and Fisher\n",
      "Davidside, AA\n",
      "\n",
      "Dispensing optician\n",
      "Bailey, Owen and Thompson\n",
      "Jamesville, AA\n",
      "\n",
      "Designer, fashion/clothing\n",
      "Vasquez Ltd\n",
      "New Kelly, AP\n",
      "\n",
      "Chartered loss adjuster\n",
      "Leblanc LLC\n",
      "Lake Antonio, AA\n",
      "\n",
      "Back-End Web Developer (Python, Django)\n",
      "Jackson, Ali and Mckee\n",
      "New Elizabethside, AA\n",
      "\n",
      "Forest/woodland manager\n",
      "Blankenship, Knight and Powell\n",
      "Millsbury, AE\n",
      "\n",
      "Clinical cytogeneticist\n",
      "Patton, Haynes and Jones\n",
      "Lloydton, AP\n",
      "\n",
      "Print production planner\n",
      "Wood Inc\n",
      "Port Jeremy, AA\n",
      "\n",
      "Systems developer\n",
      "Collins Group\n",
      "New Elizabethtown, AA\n",
      "\n",
      "Graphic designer\n",
      "Flores-Nelson\n",
      "Charlesstad, AE\n",
      "\n",
      "Writer\n",
      "Mitchell, Jones and Olson\n",
      "Josephbury, AE\n",
      "\n",
      "Field seismologist\n",
      "Howard Group\n",
      "Seanfurt, AA\n",
      "\n",
      "Chief Strategy Officer\n",
      "Kramer-Edwards\n",
      "Williambury, AA\n",
      "\n",
      "Air cabin crew\n",
      "Berry-Houston\n",
      "South Jorgeside, AP\n",
      "\n",
      "Python Programmer (Entry-Level)\n",
      "Mathews Inc\n",
      "Robertborough, AP\n",
      "\n",
      "Warden/ranger\n",
      "Riley-Johnson\n",
      "South Saratown, AP\n",
      "\n",
      "Sports therapist\n",
      "Spencer and Sons\n",
      "Hullview, AA\n",
      "\n",
      "Arts development officer\n",
      "Camacho-Sanchez\n",
      "Philipland, AP\n",
      "\n",
      "Printmaker\n",
      "Oliver and Sons\n",
      "North Patty, AE\n",
      "\n",
      "Health and safety adviser\n",
      "Eaton PLC\n",
      "North Stephen, AE\n",
      "\n",
      "Manufacturing systems engineer\n",
      "Stanley-Frederick\n",
      "Stevensland, AP\n",
      "\n",
      "Programmer, applications\n",
      "Bradley LLC\n",
      "Reyesstad, AE\n",
      "\n",
      "Medical physicist\n",
      "Parker, Goodwin and Zavala\n",
      "Bellberg, AP\n",
      "\n",
      "Media planner\n",
      "Kim-Miles\n",
      "North Johnland, AE\n",
      "\n",
      "Software Developer (Python)\n",
      "Moreno-Rodriguez\n",
      "Martinezburgh, AE\n",
      "\n",
      "Surveyor, land/geomatics\n",
      "Brown-Ortiz\n",
      "Joshuatown, AE\n",
      "\n",
      "Legal executive\n",
      "Hartman PLC\n",
      "West Ericstad, AA\n",
      "\n",
      "Librarian, academic\n",
      "Brooks Inc\n",
      "Tuckertown, AE\n",
      "\n",
      "Barrister\n",
      "Washington-Castillo\n",
      "Perezton, AE\n",
      "\n",
      "Museum/gallery exhibitions officer\n",
      "Nguyen, Yoder and Petty\n",
      "Lake Abigail, AE\n",
      "\n",
      "Radiographer, diagnostic\n",
      "Holder LLC\n",
      "Jacobshire, AP\n",
      "\n",
      "Database administrator\n",
      "Yates-Ferguson\n",
      "Port Susan, AE\n",
      "\n",
      "Furniture designer\n",
      "Ortega-Lawrence\n",
      "North Tiffany, AA\n",
      "\n",
      "Ship broker\n",
      "Fuentes, Walls and Castro\n",
      "Michelleville, AP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for job_element in job_elements:\n",
    "    title_element = job_element.find(\"h2\", class_=\"title\")\n",
    "    company_element = job_element.find(\"h3\", class_=\"company\")\n",
    "    location_element = job_element.find(\"p\", class_=\"location\")\n",
    "    print(title_element.text.strip())\n",
    "    print(company_element.text.strip())\n",
    "    print(location_element.text.strip())\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for spesific jobs on the page\n",
    "\n",
    "Following we find the job titles that include the word \"Scientist\". All the job titles are in h2 tags, therefore we use **.find_all()** to search h2 tags and string \"scientist\". Lambda function is used to convert h2 tags to lower case to remove any issues that arise with the case sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2 class=\"title is-5\">Physiological scientist</h2>, <h2 class=\"title is-5\">Audiological scientist</h2>, <h2 class=\"title is-5\">Product/process development scientist</h2>, <h2 class=\"title is-5\">Scientist, research (maths)</h2>, <h2 class=\"title is-5\">Data scientist</h2>, <h2 class=\"title is-5\">Scientist, forensic</h2>]\n"
     ]
    }
   ],
   "source": [
    "spec_jobs = results.find_all(\"h2\",string = lambda text: \"scientist\" in text.lower())\n",
    "print(spec_jobs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above result presents us with the job titles that includes the word \"scientist\". To access the other data of these job titles, we need to access 3rd level **parent** element **class=\"card-content\"** of each job. List Comprehension is used to access these data while looping through the selected jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physiological scientist\n",
      "Kramer-Klein\n",
      "South Christopher, AE\n",
      "\n",
      "Audiological scientist\n",
      "Salazar-Meyers\n",
      "Williamsburgh, AE\n",
      "\n",
      "Product/process development scientist\n",
      "Gomez-Carroll\n",
      "Marktown, AA\n",
      "\n",
      "Scientist, research (maths)\n",
      "Manning, Welch and Herring\n",
      "Laurenland, AE\n",
      "\n",
      "Data scientist\n",
      "Thomas Group\n",
      "Port Robertfurt, AA\n",
      "\n",
      "Scientist, forensic\n",
      "Gonzalez LLC\n",
      "Colehaven, AP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spec_job_elements = [\n",
    "    h2_title.parent.parent.parent for h2_title in spec_jobs\n",
    "]\n",
    "\n",
    "for job_element in spec_job_elements:\n",
    "    title_element = job_element.find(\"h2\", class_=\"title\")\n",
    "    company_element = job_element.find(\"h3\", class_=\"company\")\n",
    "    location_element = job_element.find(\"p\", class_=\"location\")\n",
    "    print(title_element.text.strip())\n",
    "    print(company_element.text.strip())\n",
    "    print(location_element.text.strip())\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basicPyProj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
